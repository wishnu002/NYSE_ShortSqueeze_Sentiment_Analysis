{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import tweepy as tw\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-nebraska",
   "metadata": {},
   "source": [
    "## Create a class that extract data from tweet object and store it to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''by: wishnu002@gmail.com'''\n",
    "\n",
    "class tweetDB:\n",
    "    '''\n",
    "    Interface class to connect this python program\n",
    "    to specified sqlite db file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dbName):\n",
    "        self.dbName = dbName   \n",
    "        \n",
    "    def openConnection(self):\n",
    "        self.connection = sqlite3.connect(self.dbName)\n",
    "        self.cursor = self.connection.cursor()\n",
    "        \n",
    "    def closeConnection(self):\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n",
    "        \n",
    "    def commitConnection(self):\n",
    "        self.connection.commit()\n",
    "        \n",
    "    def save_user(self, tweetObject):        \n",
    "               \n",
    "        self.u_id_ = tweetObject.user.id\n",
    "        self.u_name = tweetObject.user.name\n",
    "        self.u_sName = tweetObject.user.screen_name\n",
    "        \n",
    "        if tweetObject.user.location == '':\n",
    "            self.u_loc = 'Unspecified'\n",
    "        else:\n",
    "            self.u_loc = tweetObject.user.location\n",
    "        \n",
    "        self.acc_createdDate = tweetObject.user.created_at.strftime('%d-%m-%Y')\n",
    "        self.u_follower = tweetObject.user.followers_count\n",
    "        self.u_friend = tweetObject.user.friends_count        \n",
    "        self.u_verified = int(tweetObject.user.verified) #return 1 if true, 0 if false\n",
    "                \n",
    "        query = '''INSERT INTO\n",
    "        User(userid, name, screenname, location, accountcreated, follower, friend, verified)\n",
    "        VALUES (?,?,?,?,?,?,?,?);'''\n",
    "        \n",
    "        input_list = (self.u_id_, self.u_name, self.u_sName, self.u_loc,\n",
    "                      self.acc_createdDate, self.u_follower, self.u_friend, self.u_verified)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        The column 'userid' of the table 'User' in tweetDB has 'unique',\n",
    "        if duplicate is inputted, it will raise an error.\n",
    "        \n",
    "        Since we don't want any duplicates in our 'User' table, we can utilize this\n",
    "        error to ignore the insert operation.\n",
    "        '''\n",
    "        try:\n",
    "            self.cursor.execute(query, input_list)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    def save_tweet(self, tweetObject):\n",
    "        '''\n",
    "        Storing tweet data from tweet object to database,\n",
    "        one tweet object at a time\n",
    "        '''\n",
    "        \n",
    "        self.t_id = tweetObject.id\n",
    "        self.u_id =  tweetObject.user.id\n",
    "        self.t_date = tweetObject.created_at.strftime('%d-%m-%Y')\n",
    "        self.t_text = tweetObject.full_text\n",
    "        self.t_retweet = tweetObject.retweet_count\n",
    "        self.t_fave = tweetObject.favorite_count\n",
    "        \n",
    "        query = '''INSERT INTO Tweet(tweetid, userid, createddate, tweet, retweeted, favorited)\n",
    "        VALUES (?,?,?,?,?,?);'''\n",
    "        \n",
    "        input_list = (self.t_id, self.u_id, self.t_date, self.t_text, self.t_retweet, self.t_fave)\n",
    "                \n",
    "        try:\n",
    "            self.cursor.execute(query, input_list)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "    def safeExecution_save(self, tweetObject):\n",
    "        '''\n",
    "        Ensures userid in User table exist before making entry to\n",
    "        Tweet table (because there is userid FK column in tweet table)\n",
    "        '''\n",
    "        \n",
    "        self.save_user(tweetObject)\n",
    "        self.save_tweet(tweetObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-stylus",
   "metadata": {},
   "source": [
    "## Twitter mining section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_excel('twitterAPI_keys2.xlsx')\n",
    "\n",
    "api_key = keys['API_key'][0]\n",
    "api_secretKey = keys['API_secret_key'][0]\n",
    "accessToken = keys['access_token'][0]\n",
    "accessToken_secret = keys['access_token_secret'][0]\n",
    "\n",
    "auth = tw.OAuthHandler(api_key, api_secretKey)\n",
    "auth.set_access_token(accessToken, accessToken_secret)\n",
    "\n",
    "twitter = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Specifying the search query and number of\n",
    "maximum tweet data retrieved per search operation.\n",
    "'''\n",
    "\n",
    "query = '#gamestonk #gme -discord -doge -BTC -coin AND -filter:retweets'\n",
    "\n",
    "max_tweets = 4000 #max tweet per search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Result 1 (until 28-Jan-21 23:59) 1377\n",
      "Search Result 2 (until 29-Jan-21 23:59) 2092\n",
      "Search Result 3 (until 30-Jan-21 23:59) 2365\n",
      "Search Result 4 (until 31-Jan-21 23:59) 2584\n",
      "Search Result 5 (until 01-Jan-21 23:59) 3006\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tweet search \"until\" parameter are made per day to anticipate if number of search result\n",
    "of a certain day is more than the max tweet number that specified above.\n",
    "'''\n",
    "\n",
    "import time\n",
    "\n",
    "#search tweets posted before 29 Jan 2021.\n",
    "search_result1 = [status for status in tw.Cursor(twitter.search, q=query, count=100, until='2021-1-29', tweet_mode='extended').items(max_tweets)]\n",
    "#hold operation for 20 minutes (+5 minutes for safe margin) due to twitter API request limitation.\n",
    "time.sleep(1200)\n",
    "\n",
    "#search tweets posted before 30 Jan 2021\n",
    "search_result2 = [status for status in tw.Cursor(twitter.search, q=query, count=100, until='2021-1-30', tweet_mode='extended').items(max_tweets)]\n",
    "time.sleep(1200)\n",
    "\n",
    "#search tweets posted before 31 Jan 2021\n",
    "search_result3 = [status for status in tw.Cursor(twitter.search, q=query, count=100, until='2021-1-31', tweet_mode='extended').items(max_tweets)]\n",
    "time.sleep(1200)\n",
    "\n",
    "#search tweets posted before 1 Feb 2021\n",
    "search_result4 = [status for status in tw.Cursor(twitter.search, q=query, count=100, until='2021-2-1', tweet_mode='extended').items(max_tweets)]\n",
    "time.sleep(1200)\n",
    "\n",
    "#search tweets posted before 2 Feb 2021\n",
    "search_result5 = [status for status in tw.Cursor(twitter.search, q=query, count=100, until='2021-2-2', tweet_mode='extended').items(max_tweets)]\n",
    "\n",
    "print('Search Result 1 (until 28-Jan-21 23:59)', len(search_result1))\n",
    "print('Search Result 2 (until 29-Jan-21 23:59)', len(search_result2))\n",
    "print('Search Result 3 (until 30-Jan-21 23:59)', len(search_result3))\n",
    "print('Search Result 4 (until 31-Jan-21 23:59)', len(search_result4))\n",
    "print('Search Result 5 (until 01-Jan-21 23:59)', len(search_result5))\n",
    "\n",
    "'''\n",
    "Start processing on 2 Feb 2021,\n",
    "No more data mining\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create search result backup\n",
    "'''\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(search_result1, 'search_result1.sav')\n",
    "joblib.dump(search_result2, 'search_result2.sav')\n",
    "joblib.dump(search_result3, 'search_result3.sav')\n",
    "joblib.dump(search_result4, 'search_result4.sav')\n",
    "joblib.dump(search_result5, 'search_result5.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-myanmar",
   "metadata": {},
   "source": [
    "## Tweet data extraction and storing execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create an instance of tweetDB object\n",
    "'''\n",
    "\n",
    "db = tweetDB('tweet_db_gamestonk_final2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write all the result into the database file\n",
    "'''\n",
    "\n",
    "db.openConnection()\n",
    "\n",
    "for item in search_result1:\n",
    "    db.safeExecution_save(item)\n",
    "    \n",
    "for item in search_result2:\n",
    "    db.safeExecution_save(item)\n",
    "    \n",
    "for item in search_result3:\n",
    "    db.safeExecution_save(item)\n",
    "    \n",
    "for item in search_result4:\n",
    "    db.safeExecution_save(item)\n",
    "    \n",
    "for item in search_result5:\n",
    "    db.safeExecution_save(item)\n",
    "    \n",
    "db.commitConnection()\n",
    "db.closeConnection()\n",
    "\n",
    "'''\n",
    "There won't be any duplicate user and tweet entry stored in database even when\n",
    "the tweet data is overlapping between search results, thank's to the 'UNIQUE' property\n",
    "of the column 'userid' and 'tweetid' in the database.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
